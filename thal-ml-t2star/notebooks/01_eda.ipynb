{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ca7efdc",
   "metadata": {},
   "source": [
    "# 01 Â· Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510e8825",
   "metadata": {},
   "source": [
    "**Goal:** Load the CHMMOTv1 labels table, inspect distributions, define outcome bins, and export cleaned cohort + splits.\n",
    "\n",
    "> Put your labels file at `data/raw/CHMMOTv1_labels.xlsx` (or `.csv`) before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374d350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.io_utils import read_labels, ensure_dirs\n",
    "from src.preprocessing import bin_t2star_ms, make_splits, add_missing_indicators\n",
    "\n",
    "RAW = Path('data/raw')\n",
    "PROC = Path('data/processed')\n",
    "ensure_dirs(PROC)\n",
    "\n",
    "# === 1) Load ===\n",
    "labels_path = RAW / 'CHMMOTv1_labels.xlsx'  # change to your filename\n",
    "df = read_labels(labels_path)\n",
    "print(df.head())\n",
    "\n",
    "# === 2) Basic cleaning ===\n",
    "# Standardize column names (example placeholders; update to match actual columns)\n",
    "df.columns = [c.strip().lower().replace(' ', '_') for c in df.columns]\n",
    "\n",
    "# Example expected columns (adjust to your file): \n",
    "# 'patient_id', 'cardiac_t2star_ms', 'hepatic_t2star_ms', 'ferritin', 'ast', 'alt', 'alp', 'sex', 'age'\n",
    "assert 'cardiac_t2star_ms' in df.columns, \"Make sure the column 'cardiac_t2star_ms' exists\"\n",
    "\n",
    "# Outcome (example: cardiac severity bins)\n",
    "df['severity_bin'] = bin_t2star_ms(df['cardiac_t2star_ms']).astype(str)\n",
    "\n",
    "# Add missingness indicators for key labs\n",
    "lab_cols = [c for c in ['ferritin','ast','alt','alp'] if c in df.columns]\n",
    "df = add_missing_indicators(df, lab_cols)\n",
    "\n",
    "# === 3) Export cleaned cohort ===\n",
    "df.to_parquet(PROC / 'cohort_clean.parquet', index=False)\n",
    "\n",
    "# === 4) Train/valid/test splits (stratified by severity_bin) ===\n",
    "train_df, val_df, test_df = make_splits(df, y_col='severity_bin', test_size=0.2, val_size=0.2, random_state=42)\n",
    "train_df.to_parquet(PROC / 'split_train.parquet', index=False)\n",
    "val_df.to_parquet(PROC / 'split_valid.parquet', index=False)\n",
    "test_df.to_parquet(PROC / 'split_test.parquet', index=False)\n",
    "\n",
    "print('Saved processed splits to', PROC)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
